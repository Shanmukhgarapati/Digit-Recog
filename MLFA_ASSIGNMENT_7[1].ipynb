{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Backward Neural network"
      ],
      "metadata": {
        "id": "z-m9DEPx05O2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBC_ueM-BvAl"
      },
      "outputs": [],
      "source": [
        "## Name: M Sai Subrahmanya Vardhan\n",
        "## Roll:22EE10038\n",
        "\n",
        "\n",
        "# Importing Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "from sklearn.datasets import make_regression\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import load\n",
        "import numpy as np\n",
        "data=np.load('/content/imbalanced_mnist.npz')"
      ],
      "metadata": {
        "id": "pXlcrDHtCZh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(data['X_train'])\n",
        "y_train = np.array(data['y_train'])\n",
        "X_test = np.array(data['X_test'])\n",
        "y_test = np.array(data['y_test'])"
      ],
      "metadata": {
        "id": "XruwVOw_Gjjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
      ],
      "metadata": {
        "id": "nX62nT53MvNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Apply random transformation to dataset\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(size=(28, 28), padding=4),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset.transform = transform\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mI1DxdJiXIW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Code for determining best hyperparameters\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x.float()))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "input_size = 28 * 28\n",
        "output_size = 10\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Define a grid of hyperparameters\n",
        "hidden_layer_sizes = [(64, 64), (128, 128), (256, 256)]\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "best_accuracy = 0\n",
        "best_hyperparameters = None\n",
        "\n",
        "for hidden_sizes in hidden_layer_sizes:\n",
        "    for lr in learning_rates:\n",
        "        model = Net(input_size, hidden_sizes[0], hidden_sizes[1], output_size)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs = inputs.view(inputs.size(0), -1)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "\n",
        "\n",
        "            model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs = inputs.view(inputs.size(0), -1)\n",
        "                    outputs = model(inputs)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            accuracy = correct / total\n",
        "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_hyperparameters = {'hidden_layer_sizes': hidden_sizes, 'learning_rate': lr}\n",
        "\n",
        "print(f'Best hyperparameters: {best_hyperparameters}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaPO5gPxbpGo",
        "outputId": "fea1464b-36c0-41d9-adf5-ac3189c59d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5053, Accuracy: 0.6902\n",
            "Epoch [2/10], Loss: 0.2278, Accuracy: 0.9373\n",
            "Epoch [3/10], Loss: 0.1694, Accuracy: 0.9437\n",
            "Epoch [4/10], Loss: 0.1401, Accuracy: 0.8289\n",
            "Epoch [5/10], Loss: 0.1213, Accuracy: 0.9463\n",
            "Epoch [6/10], Loss: 0.1015, Accuracy: 0.9501\n",
            "Epoch [7/10], Loss: 0.0892, Accuracy: 0.9536\n",
            "Epoch [8/10], Loss: 0.0782, Accuracy: 0.9534\n",
            "Epoch [9/10], Loss: 0.0688, Accuracy: 0.9551\n",
            "Epoch [10/10], Loss: 0.0609, Accuracy: 0.9554\n",
            "Epoch [1/10], Loss: 2.6508, Accuracy: 0.1194\n",
            "Epoch [2/10], Loss: 2.2991, Accuracy: 0.1194\n",
            "Epoch [3/10], Loss: 2.2988, Accuracy: 0.1194\n",
            "Epoch [4/10], Loss: 2.1526, Accuracy: 0.2154\n",
            "Epoch [5/10], Loss: 1.9704, Accuracy: 0.2288\n",
            "Epoch [6/10], Loss: 1.9425, Accuracy: 0.2030\n",
            "Epoch [7/10], Loss: 2.2281, Accuracy: 0.1786\n",
            "Epoch [8/10], Loss: 2.1421, Accuracy: 0.1803\n",
            "Epoch [9/10], Loss: 2.2773, Accuracy: 0.1196\n",
            "Epoch [10/10], Loss: 2.2996, Accuracy: 0.1196\n",
            "Epoch [1/10], Loss: 1382193.1934, Accuracy: 0.1194\n",
            "Epoch [2/10], Loss: 2.2988, Accuracy: 0.1194\n",
            "Epoch [3/10], Loss: 2.2989, Accuracy: 0.1194\n",
            "Epoch [4/10], Loss: 2.2991, Accuracy: 0.1194\n",
            "Epoch [5/10], Loss: 2.2991, Accuracy: 0.1194\n",
            "Epoch [6/10], Loss: 2.2989, Accuracy: 0.1194\n",
            "Epoch [7/10], Loss: 2.2989, Accuracy: 0.1194\n",
            "Epoch [8/10], Loss: 2.2988, Accuracy: 0.1194\n",
            "Epoch [9/10], Loss: 2.2990, Accuracy: 0.1194\n",
            "Epoch [10/10], Loss: 2.2987, Accuracy: 0.1194\n",
            "Epoch [1/10], Loss: 0.4782, Accuracy: 0.9213\n",
            "Epoch [2/10], Loss: 0.1938, Accuracy: 0.9408\n",
            "Epoch [3/10], Loss: 0.1410, Accuracy: 0.9491\n",
            "Epoch [4/10], Loss: 0.1077, Accuracy: 0.8593\n",
            "Epoch [5/10], Loss: 0.0899, Accuracy: 0.9556\n",
            "Epoch [6/10], Loss: 0.0703, Accuracy: 0.9573\n",
            "Epoch [7/10], Loss: 0.0623, Accuracy: 0.3754\n",
            "Epoch [8/10], Loss: 0.0790, Accuracy: 0.9612\n",
            "Epoch [9/10], Loss: 0.0407, Accuracy: 0.9636\n",
            "Epoch [10/10], Loss: 0.0338, Accuracy: 0.5469\n",
            "Epoch [1/10], Loss: 44.2131, Accuracy: 0.1197\n",
            "Epoch [2/10], Loss: 2.3037, Accuracy: 0.1195\n",
            "Epoch [3/10], Loss: 2.2983, Accuracy: 0.1195\n",
            "Epoch [4/10], Loss: 2.2984, Accuracy: 0.1195\n",
            "Epoch [5/10], Loss: 2.2982, Accuracy: 0.1195\n",
            "Epoch [6/10], Loss: 2.2983, Accuracy: 0.1195\n",
            "Epoch [7/10], Loss: 2.2983, Accuracy: 0.1195\n",
            "Epoch [8/10], Loss: 2.2983, Accuracy: 0.1195\n",
            "Epoch [9/10], Loss: 2.2982, Accuracy: 0.1195\n",
            "Epoch [10/10], Loss: 2.2982, Accuracy: 0.1195\n",
            "Epoch [1/10], Loss: 1701765221428256.5000, Accuracy: 0.1194\n",
            "Epoch [2/10], Loss: 24.1416, Accuracy: 0.1194\n",
            "Epoch [3/10], Loss: 2.2991, Accuracy: 0.1194\n",
            "Epoch [4/10], Loss: 2.2988, Accuracy: 0.1194\n",
            "Epoch [5/10], Loss: 2.2989, Accuracy: 0.1194\n",
            "Epoch [6/10], Loss: 2.2991, Accuracy: 0.1194\n",
            "Epoch [7/10], Loss: 2.2990, Accuracy: 0.1194\n",
            "Epoch [8/10], Loss: 2.2992, Accuracy: 0.1194\n",
            "Epoch [9/10], Loss: 2.2990, Accuracy: 0.1194\n",
            "Epoch [10/10], Loss: 2.2987, Accuracy: 0.1194\n",
            "Epoch [1/10], Loss: 0.4634, Accuracy: 0.9280\n",
            "Epoch [2/10], Loss: 0.1571, Accuracy: 0.9466\n",
            "Epoch [3/10], Loss: 0.1021, Accuracy: 0.8078\n",
            "Epoch [4/10], Loss: 0.0712, Accuracy: 0.9568\n",
            "Epoch [5/10], Loss: 0.0487, Accuracy: 0.9569\n",
            "Epoch [6/10], Loss: 0.0337, Accuracy: 0.9605\n",
            "Epoch [7/10], Loss: 0.0245, Accuracy: 0.9609\n",
            "Epoch [8/10], Loss: 0.0179, Accuracy: 0.9612\n",
            "Epoch [9/10], Loss: 0.0131, Accuracy: 0.9622\n",
            "Epoch [10/10], Loss: 0.0099, Accuracy: 0.9624\n",
            "Epoch [1/10], Loss: nan, Accuracy: 0.1041\n",
            "Epoch [2/10], Loss: nan, Accuracy: 0.1041\n",
            "Epoch [3/10], Loss: nan, Accuracy: 0.1041\n",
            "Epoch [4/10], Loss: nan, Accuracy: 0.1041\n",
            "Epoch [5/10], Loss: nan, Accuracy: 0.1041\n",
            "Epoch [6/10], Loss: nan, Accuracy: 0.1041\n",
            "Epoch [7/10], Loss: nan, Accuracy: 0.1041\n",
            "Epoch [8/10], Loss: nan, Accuracy: 0.1041\n",
            "Epoch [9/10], Loss: nan, Accuracy: 0.1041\n",
            "Epoch [10/10], Loss: nan, Accuracy: 0.1041\n",
            "Epoch [1/10], Loss: 319450127522431488.0000, Accuracy: 0.1194\n",
            "Epoch [2/10], Loss: 2.2991, Accuracy: 0.1194\n",
            "Epoch [3/10], Loss: 2.2986, Accuracy: 0.1194\n",
            "Epoch [4/10], Loss: 2.2989, Accuracy: 0.1194\n",
            "Epoch [5/10], Loss: 2.2990, Accuracy: 0.1194\n",
            "Epoch [6/10], Loss: 2.2991, Accuracy: 0.1194\n",
            "Epoch [7/10], Loss: 2.2990, Accuracy: 0.1041\n",
            "Epoch [8/10], Loss: 2.2990, Accuracy: 0.1194\n",
            "Epoch [9/10], Loss: 2.2989, Accuracy: 0.1194\n",
            "Epoch [10/10], Loss: 2.2990, Accuracy: 0.1194\n",
            "Best hyperparameters: {'hidden_layer_sizes': (128, 128), 'learning_rate': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Best hyperparameters and plotting for train and validation data\n",
        "input_size = 28 * 28\n",
        "output_size = 10\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "hidden_sizes = (128, 128)\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(size=(28, 28), padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "model = Net(input_size, hidden_sizes[0], hidden_sizes[1], output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.view(inputs.size(0), -1)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_train_loss += loss.item()\n",
        "    train_losses.append(running_train_loss / len(train_loader))\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.view(inputs.size(0), -1)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_val_loss += loss.item()\n",
        "    val_losses.append(running_val_loss / len(val_loader))\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}')\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.size(0), -1)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = correct / total\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Visualize the training and validation loss graphs\n",
        "plt.plot(range(1, epochs + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, epochs + 1), val_losses, label='Val Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "5Yl6_zRKj6V7",
        "outputId": "b19427ee-c0d1-4ab5-adc5-8a933145b810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.4738, Val Loss: 0.2627\n",
            "Epoch [2/10], Train Loss: 0.1935, Val Loss: 0.2085\n",
            "Epoch [3/10], Train Loss: 0.1369, Val Loss: 0.1816\n",
            "Epoch [4/10], Train Loss: 0.1056, Val Loss: 0.1756\n",
            "Epoch [5/10], Train Loss: 0.0843, Val Loss: 0.1748\n",
            "Epoch [6/10], Train Loss: 0.0695, Val Loss: 0.1572\n",
            "Epoch [7/10], Train Loss: 0.0561, Val Loss: 0.1526\n",
            "Epoch [8/10], Train Loss: 0.0454, Val Loss: 0.1537\n",
            "Epoch [9/10], Train Loss: 0.0375, Val Loss: 0.1614\n",
            "Epoch [10/10], Train Loss: 0.0304, Val Loss: 0.1572\n",
            "Test Accuracy: 0.9603\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchprofile\n",
        "!pip install torchmetrics\n",
        "from torchprofile import profile_macs\n",
        "from torchmetrics import ConfusionMatrix, Precision, Recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB2Jm9l7zDuA",
        "outputId": "d11dd2be-3bf5-4fc9-a454-6c133e93613f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchprofile\n",
            "  Downloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m567.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->torchprofile)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.4->torchprofile) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->torchprofile) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchprofile\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torchprofile-0.0.4\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.2 torchmetrics-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## To print total presicion,confussion matrix and recall score\n",
        "input_size = 28 * 28\n",
        "output_size = 10\n",
        "hidden_sizes = (128, 128)\n",
        "\n",
        "model = Net(input_size, hidden_sizes[0], hidden_sizes[1], output_size)\n",
        "\n",
        "\n",
        "confusion_matrix = ConfusionMatrix(num_classes=output_size, task='MULTICLASS')\n",
        "\n",
        "\n",
        "precision = Precision(num_classes=output_size, task='MULTICLASS')\n",
        "\n",
        "\n",
        "recall = Recall(num_classes=output_size, task='MULTICLASS')\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs = inputs.view(inputs.size(0), -1)\n",
        "            outputs = model(inputs)\n",
        "            confusion_matrix.update(outputs, labels)\n",
        "            precision.update(outputs, labels)\n",
        "            recall.update(outputs, labels)\n",
        "\n",
        "\n",
        "evaluate(model, test_loader)\n",
        "\n",
        "\n",
        "cm = confusion_matrix.compute().cpu().numpy()\n",
        "prec = precision.compute().cpu().numpy()\n",
        "rec = recall.compute().cpu().numpy()\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\n\")\n",
        "print(\"Precision:\")\n",
        "print(prec)\n",
        "print(\"\\n\")\n",
        "print(\"Recall:\")\n",
        "print(rec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81GYQq68qMNQ",
        "outputId": "9dc09ec1-c375-498a-b823-0c018ebff6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[215   1   7   3   0   1 648   0  49  56]\n",
            " [ 38   2   1   0   0   0 611   0 472  11]\n",
            " [128   5   8  49   0   1 543   5 211  82]\n",
            " [126   0  13   1   0   0 757   5  58  50]\n",
            " [146   2  11   2   0   1 571   0  67 182]\n",
            " [ 82   0  28   0   0   4 641   1  25 111]\n",
            " [ 79   0  15   9   0  10 474   1 118 252]\n",
            " [177   2  13   5   0   2 371   0 148 310]\n",
            " [125   1  26   7   0   0 733   0  33  49]\n",
            " [189   2  14   6   0   7 416   0  30 345]]\n",
            "\n",
            "\n",
            "Precision:\n",
            "0.1082\n",
            "\n",
            "\n",
            "Recall:\n",
            "0.1082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Printing flops and params\n",
        "!pip install flopth\n",
        "from flopth import flopth\n",
        "flops, params = flopth(model, in_size=(784,),show_detail=True)\n",
        "print(flops, params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAmH16XYzuBp",
        "outputId": "343f5af9-3b1c-4234-f558-475eb4f9dca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flopth in /usr/local/lib/python3.10/dist-packages (0.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from flopth) (1.25.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from flopth) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flopth) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from flopth) (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->flopth) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flopth) (12.4.127)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->flopth) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flopth) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flopth) (1.3.0)\n",
            "+---------------+---------------+------------+-------------+------------------------------+----------+------------------+--------------------------------------------+----------+-----------------+--------------------------------------------+\n",
            "| module_name   | module_type   | in_shape   | out_shape   | kernel_size,padding,stride   | params   | params_percent   | params_percent_vis                         | flops    | flops_percent   | flops_percent_vis                          |\n",
            "+===============+===============+============+=============+==============================+==========+==================+============================================+==========+=================+============================================+\n",
            "| fc1           | Linear        | (784)      | (128)       |                              | 100.48K  | 84.9495%         | ########################################## | 100.352K | 84.9404%        | ########################################## |\n",
            "+---------------+---------------+------------+-------------+------------------------------+----------+------------------+--------------------------------------------+----------+-----------------+--------------------------------------------+\n",
            "| fc2           | Linear        | (128)      | (128)       |                              | 16.512K  | 13.9599%         | ######                                     | 16.384K  | 13.8678%        | ######                                     |\n",
            "+---------------+---------------+------------+-------------+------------------------------+----------+------------------+--------------------------------------------+----------+-----------------+--------------------------------------------+\n",
            "| fc3           | Linear        | (128)      | (10)        |                              | 1.29K    | 1.09061%         |                                            | 1.28K    | 1.08342%        |                                            |\n",
            "+---------------+---------------+------------+-------------+------------------------------+----------+------------------+--------------------------------------------+----------+-----------------+--------------------------------------------+\n",
            "| relu          | ReLU          | (128)      | (128)       |                              | 0.0      | 0.0%             |                                            | 128.0    | 0.108342%       |                                            |\n",
            "+---------------+---------------+------------+-------------+------------------------------+----------+------------------+--------------------------------------------+----------+-----------------+--------------------------------------------+\n",
            "\n",
            "\n",
            "118.144K 118.282K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    # First convolutional layer\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second convolutional layer\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten the output and feed it into a dense layer\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQAgDZcpYQi6",
        "outputId": "a346965f-33b1-4e93-991f-427ea0f7dcb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 76s 40ms/step - loss: 0.1415 - accuracy: 0.9567 - val_loss: 0.0491 - val_accuracy: 0.9842\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 53s 29ms/step - loss: 0.0448 - accuracy: 0.9859 - val_loss: 0.0371 - val_accuracy: 0.9885\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0303 - val_accuracy: 0.9900\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0307 - val_accuracy: 0.9903\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.0313 - val_accuracy: 0.9908\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0313 - accuracy: 0.9908\n",
            "Test accuracy: 0.9908000230789185\n"
          ]
        }
      ]
    }
  ]
}